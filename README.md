# ðŸ§  Text Representation in NLP

This project delves into various techniques for representing text data in Natural Language Processing (NLP). It covers foundational methods like Bag of Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF). The goal is to provide a comprehensive understanding of how different text representation methods can be implemented and compared. This is part-1 of the text representation series, which covers just the basics of how text can be represented in Vector form. The notebook covers the concepts in detail using examples and code. Vectorizing techniques are also been coded from scratch for better understanding.

# ðŸ“‚ Project Structure

```
ðŸ“‚ TextRepresentationNLP/
â”œâ”€â”€ Text_representation/
â”‚   â”œâ”€â”€ nlp2_text_repre_medium_article.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ medium_articles_v3.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


ðŸš€ Getting Started

## Prerequisites

- Python 3.7 or higher
- Jupyter Notebook

## Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/theCuriousHAT/TextRepresentationNLP.git
    cd TextRepresentationNLP
    ```

2. Create a virtual environment (optional but recommended):

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3. Install the required packages:

    ```bash
    pip install -r requirements.txt
    ```

4. Launch Jupyter Notebook:

    ```bash
    jupyter notebook
    ```




